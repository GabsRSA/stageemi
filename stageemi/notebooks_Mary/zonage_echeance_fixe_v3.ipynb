{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import xarray as xr \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import sys, os\n",
    "import string\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('./lib'))\n",
    "\n",
    "from lib import hss,precision #,far,f1, pod,pofd\n",
    "from lib import create_combination_subzones, create_nc_mask_NSEO\n",
    "from lib import find_neighbours, group_masks_size, select_group_mask, get_WME_legend, get_not_included_masks\n",
    "\n",
    "import stageemi\n",
    "import stageemi.dev.distance_wwmf as distance_wwmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_subzone_v2(ds_WME, groupe_mask_select,cible):\n",
    "    \"\"\"\n",
    "        ds_WME  = xarray contenant les champs WME\n",
    "        cible = valeur du temps sensible cible (par exemple code WME)\n",
    "        groupe_mask_select = ensemble de masks qui vont être comparés à l'objet météo\n",
    "        ds_mask = La liste de masques\n",
    "    \"\"\"\n",
    "    score_precision = np.zeros(len(groupe_mask_select.mask))    \n",
    "    score_hss       = np.zeros(len(groupe_mask_select.mask)) \n",
    "\n",
    "    for imask,ds_mask_sub in enumerate(groupe_mask_select.mask):    \n",
    "        # check if latitudes are aranged in the the same way\n",
    "        lat1 = ds_mask_sub.latitude.values\n",
    "        lat2 = ds_WME.latitude.values\n",
    "        if (np.sum(lat1==lat2) == lat1.size ): \n",
    "            # same order \n",
    "            y_true = ds_WME.wme_arr.copy()\n",
    "        elif (np.sum(lat1[::-1]==lat2)== lat1.size):\n",
    "            # reverse order\n",
    "            y_true = ds_WME.wme_arr[::-1,:].copy()\n",
    "        else: \n",
    "            print(\"pb sur lon/lat\")\n",
    "            break\n",
    "        y_pred = ds_mask_sub.copy() \n",
    "        # binarise\n",
    "        y_true = y_true.where(~((y_true.values!=cible) & (~np.isnan(y_true.values))),0)#ds_dep.wme_arr.copy()\n",
    "        y_true = y_true.where(~(y_true.values == cible), 1)\n",
    "        y_true_score = y_true.values[~np.isnan(y_true.values)]\n",
    "        y_pred_score = y_pred.values[~np.isnan(y_pred.values)]\n",
    "    #     print(y_true_score,y_pred_score )\n",
    "        # metriques : \n",
    "        score_precision[imask] = precision(y_true_score,y_pred_score)\n",
    "        score_hss[imask]       = hss(y_true_score,y_pred_score)\n",
    "\n",
    "    ind_nan = np.where((~np.isnan(score_hss))*(score_hss>0))\n",
    "\n",
    "    # car si hss <0, alors le hasard fait mieux les choses\n",
    "    if np.size(ind_nan[0])== 0 :\n",
    "        # signifie qu'il y a aucune zone qui représente bien la cible\n",
    "        print('pas de zones homogène pour {}'.format(cible))\n",
    "        zones_optimales_f,hss_f,precision_f = [],[],[] \n",
    "    elif np.size(ind_nan[0])== 1 : \n",
    "        # une seule zone possible\n",
    "        zones_optimales_f = [groupe_mask_select.id.values[ind_nan][0]]\n",
    "        hss_f             = [score_hss[ind_nan][0]]\n",
    "        precision_f       = [score_precision[ind_nan][0]]\n",
    "\n",
    "    else: \n",
    "\n",
    "        # selection de la zone qui maximise le hss\n",
    "        indice = np.argmax(score_hss[ind_nan]) \n",
    "        zones_optimales_f = [groupe_mask_select.id.values[ind_nan][indice]]\n",
    "        hss_f             = [score_hss[ind_nan][indice]]\n",
    "        precision_f       = [score_precision[ind_nan][indice]] \n",
    "        mask_ref          =  groupe_mask_select.sel(id=zones_optimales_f[0]).mask\n",
    "        # on cherche les zones non-incluses dans cette zone pour aller chercher le deuxième meilleur hss\n",
    "        lst_mask_not_included, lst_mask_included = get_not_included_masks(mask_ref, groupe_mask_select.id.values[ind_nan],\n",
    "                                                    groupe_mask_select,flag_strictly_included=False)\n",
    "        print(zones_optimales_f[0],lst_mask_not_included)\n",
    "        if(len(lst_mask_not_included)>0):\n",
    "            score_hss2 = [score_hss[ind_nan][groupe_mask_select.id.values[ind_nan] == mask_id] for mask_id in lst_mask_not_included]\n",
    "            score_precision2 = [score_precision[ind_nan][groupe_mask_select.id.values[ind_nan] == mask_id] for mask_id in lst_mask_not_included]\n",
    "            list_mask2 = [groupe_mask_select.id.values[ind_nan][groupe_mask_select.id.values[ind_nan] == mask_id] for mask_id in lst_mask_not_included]\n",
    "            indice2 = np.argmax(score_hss2)    \n",
    "            if score_precision2[indice2]>0.2 and \\\n",
    "                np.abs(score_hss[ind_nan][indice] - score_hss2[indice2]) / score_hss[ind_nan][indice] <0.2:\n",
    "                zones_optimales_f.append(list_mask2[indice2].tolist()[0]) #groupe_mask_select.id.values[ind_nan][indice2])\n",
    "                hss_f.append(score_hss2[indice2])\n",
    "                precision_f.append(score_precision2[indice2] )\n",
    "    return zones_optimales_f,hss_f,precision_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['legend.handlelength'] = 0\n",
    "matplotlib.rcParams['legend.numpoints'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dep_id 29\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mary\\anaconda3\\envs\\preproc\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# On obtient un zonage par departement par echeance.\n",
    "\n",
    "''' input '''\n",
    "date = '2020012600' # Date pour laquelle on fait tourner \n",
    "# date = '2020030600'\n",
    "list_method_distance = ['compas']#,'agat','compas_asym','agat_asym'] # pour agreger le temps sensible\n",
    "\n",
    "mask_sympo = False # Veut-on des combie de zones sympos ? \n",
    "mask_geographique = True # Veut-on des combinaisons Est/Ouest/Nord/Sud. A rebrancher. \n",
    "mask_sympo = True # Veut-on des combie de zones sympos ? \n",
    "mask_geographique = False # Veut-on des combinaisons Est/Ouest/Nord/Sud. A rebrancher. \n",
    "\n",
    "\n",
    "dir_fig = '../figures/total/' \n",
    "nsubzonesMax = 4 # Nombre de sous zones \n",
    "plot_results = False\n",
    "Force = False # Force to recompute staff \n",
    "if date == '2020012600':\n",
    "#     echeance_dict = {\n",
    "#         '38':[44,12,3,46,43,25,30],\n",
    "#         '29':[32,39,20,33,13],  \n",
    "#         '34':[1,5,6,4 ,10, 20,30], \n",
    "#         '41':[45,4,44,5,20,30]\n",
    "#     }\n",
    "        echeance_dict = {\n",
    "#             '38':[44,43,3,46,30],\n",
    "#             '41':[45,4]#,44,5,20,30]\n",
    "            '29':[32]\n",
    "    }\n",
    "elif date == '2020030600':\n",
    "    echeance_dict = {\n",
    "        '38':[29,3,1,4,36],\n",
    "        '41':[18],\n",
    "        '29':[1,5,3],  \n",
    "        '34':[31,6,16,29,30], \n",
    "    }\n",
    "    \n",
    "for dep_id in echeance_dict.keys():\n",
    "    echeance_list = echeance_dict[dep_id]\n",
    "    print('dep_id',dep_id)\n",
    "    ''' lecture fichier arome '''\n",
    "    fname = \"../WWMF/\" + date+'0000__PG0PAROME__'+'WWMF'+'__EURW1S100______GRILLE____0_48_1__SOL____GRIB2.nc'\n",
    "    ds = xr.open_dataset(fname,chunks={\"step\":1}).isel(step = echeance_list)\n",
    "    # Arrondi pour éviter les erreurs     \n",
    "    ds['latitude']  = ds['latitude'].round(5)\n",
    "    ds['longitude'] = ds['longitude'].round(5)\n",
    "    if date == '2020030600':\n",
    "        ds = ds.rename({'paramId_0':'unknown'})\n",
    "    \n",
    "\n",
    "        \n",
    "    ''' lecture du mask '''\n",
    "    if mask_sympo and not mask_geographique:         \n",
    "        fname_out = '../GeoData/zones_sympo_multiples/'+dep_id+'_mask_zones_sympos.nc'\n",
    "        if not os.path.exists(fname_out): \n",
    "            # Creation du fichier (netcdf) de combinaison des zones sympos \n",
    "            dir_mask = '/home/mrpa/borderiesm/stageEMI/Codes/StageEMI/Masques_netcdf/ZONE_SYMPO/'\n",
    "            list_subzones = glob.glob(dir_mask + dep_id +'*.nc')\n",
    "            n_subzones = len(list_subzones)  # nombre de zones sympos initiales\n",
    "            lst_subzones = [zone[-7:-3] for zone in list_subzones]\n",
    "            ds_mask = create_combination_subzones(dir_mask,dep_id,lst_subzones,fname_out,degre5=True) \n",
    "            ds_mask = ds_mask.chunk({\"id\":1}) # Rend le calcul parallele possible \n",
    "        else: \n",
    "            # Le fichier est disponible \n",
    "            ds_mask = xr.open_dataset(fname_out,chunks={\"id\":1})\n",
    "        dir_out = '../zonageWME/v7_'+'WME_' # repertoire contenant les fichiers résultats du zonage\n",
    "        id_dep = 'departement' # identifiant de la zone recouvrant tout le departement\n",
    "    if mask_geographique and not mask_sympo: \n",
    "        if   dep_id == '38': dep = 'FRK24'\n",
    "        elif dep_id == '41': dep = 'FRB05'\n",
    "        elif dep_id == \"34\": dep = 'FRJ13'\n",
    "        elif dep_id == '29': dep = \"FRH02\"\n",
    "        else: \n",
    "            print('remplir la bonne valeur pour le dep')\n",
    "            sys.exit()\n",
    "        fname_out = '../GeoData/zones_sympo_multiples/'+ dep_id+'_'+dep+'_mask_NSEO.nc'\n",
    "        if not os.path.exists(fname_out):\n",
    "            # Creation du fichier (netcdf) s'il n'existe pas \n",
    "            dir_mask  = '../GeoData/nc_departement/'\n",
    "            dep_file  = dir_mask + dep +'.nc' \n",
    "            print('on cree',fname_out)\n",
    "            ds_mask = create_nc_mask_NSEO(dep_file,fname_out,plot_dep=False)\n",
    "            ds_mask = ds_mask.chunk({\"id\":1})\n",
    "        else:\n",
    "            ds_mask = xr.open_dataset(fname_out,chunks={\"id\":1})\n",
    "        dir_out = '../zonageWME/v7_'+'geo_' # repertoire contenant les fichiers résultats du zonage\n",
    "        id_dep = '0+1+2+3+4+5+6+7+8'# identifiant de la zone recouvrant tout le departement\n",
    "    sys.exit()    \n",
    "    # Arrondi pour éviter les erreurs         \n",
    "    ds_mask[\"latitude\"]  = ds_mask[\"latitude\"].round(5)\n",
    "    ds_mask[\"longitude\"] = ds_mask[\"longitude\"].round(5)\n",
    "    ds_dep_tot = (ds*ds_mask.mask.sel(id=id_dep))\n",
    "   \n",
    "    ''' calcul des temps agrégés '''\n",
    "    ds_distance_dict = {}\n",
    "    for name in list_method_distance:\n",
    "        ds_distance         = distance_wwmf.get_pixel_distance_dept(ds_dep_tot,name) # rajoute les variables wme_arr et w1_arr\n",
    "        ds_distance_chunk   = ds_distance.chunk({\"step\":1}) \n",
    "        # On recupere ici toute les zones. \n",
    "        ds_distance_dict[name] = (ds_distance_chunk * ds_mask.mask).sum(['latitude',\"longitude\"]).compute()\n",
    "    print('fin calcul distance')\n",
    "   \n",
    "    # On part toujours sur l'utilisation des dénominations COMPAS car elles sont moins nombreuses?  \n",
    "    var_name = 'wme_arr'\n",
    "    for icheance,echeance in enumerate(echeance_list): \n",
    "        print(echeance)\n",
    "        fname_out = dir_out+dep_id+'_'+date+'_'+str(echeance)+'.csv'\n",
    "\n",
    "        if os.path.exists(fname_out) and not Force:\n",
    "            print(fname_out,'existe')\n",
    "            continue\n",
    "        \n",
    "        tdeb = time.time()\n",
    "        ''' on restreint la liste des WME pour le zonage '''\n",
    "        ds_dep = ds_dep_tot.isel(step = icheance).copy()\n",
    "        # on regroupe 'Très nuageux/Couvert' et 'Nuageux'\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 2) + (ds_dep[var_name].values == 3) ), 2)\n",
    "        # on regroupe ensemble neige (10) et neige faible (7)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 7) + (ds_dep[var_name].values == 10)), 10)\n",
    "        # on regroupe ensemble pluie (8) et pluie faible (6)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 8) + (ds_dep[var_name].values == 6)),8)\n",
    "        # on regroupe ensemble qlqs averses (12) et averses (14), et qlqs averses de neige (13)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 12) + (ds_dep[var_name].values == 13)\n",
    "                                  + (ds_dep[var_name].values == 14 )),14)\n",
    "        # on regroupe ensemble averses Orageuses (16) et Orages  (18)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 16) + (ds_dep[var_name].values == 18)),18)\n",
    "\n",
    "        file_CodesWWMF = '../utils/CodesWWMF.csv'\n",
    "        cible_list,legend_list = get_WME_legend(file_CodesWWMF, ds_dep) \n",
    "\n",
    "        ''' zonage '''\n",
    "        listCible    = cible_list[::-1] # On considère que l'ordre inverse est l'ordre de criticité maximun.\n",
    "                                        # A bien définir lors de l'utilisation selon les cas.  \n",
    "\n",
    "        legend_cible = [] # pour stocker la légende du code WME\n",
    "        listMasksNew = ds_mask.id.values # on commence avec l'ensemble des masks\n",
    "\n",
    "        # liste de zones sympos initiales (pour checker à la fin si on a une info sur toutes les zones du département)\n",
    "        list_zones_sympos_initiales = [zone for zone in ds_mask.id.values if (('+' not in zone) and (zone!='departement'))]\n",
    "        \n",
    "        nsubzones    = 0\n",
    "        zones_cibles = {}\n",
    "        score_zones_cibles = {}\n",
    "        if len(listCible) == 0 : # si un département a le même temps sensible partout\n",
    "            zones_cibles[listCible[0]] = 'departement'\n",
    "        else: \n",
    "            for icible,cible in enumerate(listCible):\n",
    "                if nsubzones > nsubzonesMax: \n",
    "                    print('nombre de sous-zones trop grand')\n",
    "                    break \n",
    "                if nsubzones >1: \n",
    "                    # pour éviter que departement ne soit selectionné alors que des sous-zones de departement aient déjà été selectionnées.\n",
    "                    listMasksNew = [element for element in listMasksNew if element !=id_dep ]\n",
    "\n",
    "                if len(listMasksNew)>60:\n",
    "                    #  on regroupe les masks selon leur taille pour aller plus vite \n",
    "                    groupe1,groupe2,groupe3,taille1,taille2  = group_masks_size(listMasksNew,ds_mask)\n",
    "                    # on selectionne le groupement de zones qui match l'objet météo\n",
    "                    groupe_mask_select = select_group_mask(ds_dep,cible,groupe1,groupe2,groupe3,taille1,taille2)\n",
    "                else: \n",
    "                    # on considère l'ensemble des masks\n",
    "                    groupe_mask_select = ds_mask.sel(id=listMasksNew) \n",
    "                # on selectionne la zone optimale (selon le hss et la précision)\n",
    "                zones_optimales,score_hss,score_precision=get_optimal_subzone_v2(ds_dep, groupe_mask_select,cible)              \n",
    "                if len(zones_optimales)!=0:\n",
    "                    legend_cible.append(legend_list[::-1][icible])\n",
    "                    score_zones_cibles[cible] = score_hss\n",
    "                    zones_cibles[cible] = zones_optimales \n",
    "                    nsubzones +=1 \n",
    "                    # sinon pas de zones selectionnées                                            \n",
    "                    ''' on check que la somme des zones n'est pas déjà égale au departement '''\n",
    "                    if  (nsubzones== 1) and (len(zones_cibles[cible]) == 1) :\n",
    "                        ds_temp  = ds_mask.sel(id=zones_cibles[cible][0]).mask.copy()\n",
    "\n",
    "                    elif (nsubzones== 1) and (len(zones_cibles[cible]) > 1): \n",
    "    #                    ds_temp  = ds_mask.sel(id=zones_cibles[cible]).mask.sum(\"id\") >= 1  \n",
    "                        ds_temp  = ds_mask.sel(id=zones_cibles[cible][0]).mask.copy() \n",
    "                        ds_temp.values[(ds_temp.values == 1) + (ds_mask.sel(id=zones_cibles[cible][1]).mask.values ==1) ] = 1\n",
    "                    else: \n",
    "                        for zone in zones_cibles[cible]:                            \n",
    "                            ds_temp.values[(ds_temp.values == 1) + (ds_mask.sel(id=zone).mask.values ==1) ] = 1\n",
    "\n",
    "                    somme = np.sum((ds_temp.values == 1)&( ds_mask.sel(id=id_dep).mask.values== 1))\n",
    "                    tailleDep = np.sum( ds_mask.sel(id=id_dep).mask.values== 1)\n",
    "                    if somme == tailleDep: \n",
    "                        print('on a atteint la taille du departement')\n",
    "                        break\n",
    "                    # on récupère les zones non-incluses dans la zone sélectionnée\n",
    "                    for zone in zones_cibles[cible]:\n",
    "                        listMasksNew, lst_mask_included = get_not_included_masks(ds_mask.mask.sel(id=zone)\n",
    "                                                        ,listMasksNew,ds_mask,flag_strictly_included=False)\n",
    "            # fin boucle sur cible\n",
    "            ''' on vérifie que toutes les zones du département sont dans les zones selectionnées '''\n",
    "            list_zones_select = sum([zones_cibles[cible] for cible in zones_cibles.keys()],[]) \n",
    "            zones_restantes = []\n",
    "            for zone_sympo in list_zones_sympos_initiales:\n",
    "                n = 0\n",
    "                for zone_select in list_zones_select: \n",
    "                    if zone_sympo in zone_select:\n",
    "                        n+=1\n",
    "                if n == 0 : \n",
    "                    zones_restantes.append(zone_sympo)\n",
    "        \n",
    "        print(zones_cibles)   \n",
    "        print(zones_restantes)\n",
    "        \n",
    "        '''save results in csv'''\n",
    "        print('saving results')\n",
    "        \n",
    "        d = { 'zone':sum([zones_cibles[cible] for cible in zones_cibles.keys()],[]), \n",
    "            'cible_wme':sum([[cible]  if len(zones_cibles[cible])==1 else [cible,cible] for cible in zones_cibles.keys()],[]),\n",
    "            'hss' : sum([score_zones_cibles[cible] for cible in zones_cibles.keys()],[])}\n",
    "\n",
    "        if len(zones_restantes)>0:\n",
    "            d['zone'] += zones_restantes\n",
    "            d['hss'] += [np.nan for i in range(len(zones_restantes))]\n",
    "            d['cible_wme'] += [np.nan for i in range(len(zones_restantes))]\n",
    "        for name in list_method_distance:\n",
    "            d[name] =  ds_distance_dict[name].wwmf_2[ds_distance_dict[name].argmin(\"wwmf_2\")].sel(id=d['zone']).isel(step=icheance).values\n",
    "        pd.DataFrame(data=d).to_csv(fname_out)\n",
    "        print('temps %s \\n'%(time.time()-tdeb))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3805 ['3801', '3803', '3806', '3801+3802', '3801+3803', '3802+3803', '3803+3806', '3804+3806', '3806+3808', '3801+3802+3803', '3801+3802+3804', '3801+3803+3804', '3801+3803+3806', '3802+3803+3806', '3802+3804+3806', '3803+3804+3806', '3803+3806+3808', '3804+3806+3808', '3801+3803+3804+3808', '3801+3803+3806+3808', '3802+3803+3806+3808', '3802+3804+3806+3808', '3803+3804+3806+3808']\n",
      "3801+3802+3803\n",
      "0.09267086622461079\n",
      "0.6535123596341857\n"
     ]
    }
   ],
   "source": [
    "listMasksNew = ds_mask.id.values\n",
    "\n",
    "listMasksNew, lst_mask_included = get_not_included_masks(ds_mask.mask.sel(id='3801+3802')\n",
    "                                                        ,listMasksNew,ds_mask,flag_strictly_included=False)\n",
    "\n",
    "\n",
    "ds_WME = ds_dep.copy()\n",
    "cible = 14\n",
    "\n",
    "score_precision = np.zeros(len(groupe_mask_select.mask))    \n",
    "score_hss       = np.zeros(len(groupe_mask_select.mask)) \n",
    "\n",
    "for imask,ds_mask_sub in enumerate(groupe_mask_select.mask):    \n",
    "    # check if latitudes are aranged in the the same way\n",
    "    lat1 = ds_mask_sub.latitude.values\n",
    "    lat2 = ds_WME.latitude.values\n",
    "    if (np.sum(lat1==lat2) == lat1.size ): \n",
    "        # same order \n",
    "        y_true = ds_WME.wme_arr.copy()\n",
    "    elif (np.sum(lat1[::-1]==lat2)== lat1.size):\n",
    "        # reverse order\n",
    "        y_true = ds_WME.wme_arr[::-1,:].copy()\n",
    "    else: \n",
    "        print(\"pb sur lon/lat\")\n",
    "        break\n",
    "    y_pred = ds_mask_sub.copy() \n",
    "    # binarise\n",
    "    y_true = y_true.where(~((y_true.values!=cible) & (~np.isnan(y_true.values))),0)#ds_dep.wme_arr.copy()\n",
    "    y_true = y_true.where(~(y_true.values == cible), 1)\n",
    "    y_true_score = y_true.values[~np.isnan(y_true.values)]\n",
    "    y_pred_score = y_pred.values[~np.isnan(y_pred.values)]\n",
    "    # metriques : \n",
    "    score_precision[imask] = precision(y_true_score,y_pred_score)\n",
    "    score_hss[imask]       = hss(y_true_score,y_pred_score)\n",
    "\n",
    "ind_nan = np.where((~np.isnan(score_hss))*(score_hss>0))\n",
    "\n",
    "# car si hss <0, alors le hasard fait mieux les choses\n",
    "if np.size(ind_nan[0])== 0 :\n",
    "    # signifie qu'il y a aucune zone qui représente bien la cible\n",
    "    print('pas de zones homogène pour {}'.format(cible))\n",
    "    zones_optimales_f,hss_f,precision_f = [],[],[] \n",
    "elif np.size(ind_nan[0])== 1 : \n",
    "    # une seule zone possible\n",
    "    zones_optimales_f = [groupe_mask_select.id.values[ind_nan][0]]\n",
    "    hss_f             = [score_hss[ind_nan][0]]\n",
    "    precision_f       = [score_precision[ind_nan][0]]\n",
    "\n",
    "else: \n",
    "\n",
    "    # selection de la zone qui maximise le hss\n",
    "    indice = np.argmax(score_hss[ind_nan]) \n",
    "    zones_optimales_f = [groupe_mask_select.id.values[ind_nan][indice]]\n",
    "    hss_f             = [score_hss[ind_nan][indice]]\n",
    "    precision_f       = [score_precision[ind_nan][indice]] \n",
    "    mask_ref          =  groupe_mask_select.sel(id=zones_optimales_f[0]).mask\n",
    "    # on cherche les zones non-incluses dans cette zone pour aller chercher le deuxième meilleur hss\n",
    "    lst_mask_not_included, lst_mask_included = get_not_included_masks(mask_ref, groupe_mask_select.id.values[ind_nan],\n",
    "                                                groupe_mask_select,flag_strictly_included=False)\n",
    "    print(zones_optimales_f[0],lst_mask_not_included)\n",
    "    if(len(lst_mask_not_included)>0):\n",
    "        indice2 = np.argmax([score_hss[ind_nan][groupe_mask_select.id.values[ind_nan] == mask_id] for mask_id in lst_mask_not_included])\n",
    "\n",
    "        if score_precision[ind_nan][indice2]>0.2 and \\\n",
    "            np.abs(score_hss[ind_nan][indice] - score_hss[ind_nan][indice2]) / score_hss[ind_nan][indice] <0.2:\n",
    "            zones_optimales_f.append(groupe_mask_select.id.values[ind_nan][indice2])\n",
    "            print(zones_optimales_f,groupe_mask_select.id.values[ind_nan][indice],groupe_mask_select.id.values[ind_nan][indice2])\n",
    "            hss_f.append(score_hss[ind_nan][indice2])\n",
    "            precision_f  = [score_precision[ind_nan][indice2]] \n",
    "        else: \n",
    "            print(groupe_mask_select.id.values[ind_nan][indice2])\n",
    "            print(score_hss[ind_nan][indice2])\n",
    "            print(  np.abs(score_hss[ind_nan][indice] - score_hss[ind_nan][indice2]) / score_hss[ind_nan][indice] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.exit()\n",
    "''' input '''\n",
    "date = '2020012600'\n",
    "# date = '2020030600'\n",
    "list_name = ['compas'] #,'agat','compas_asym','agat_asym'] # pour agreger le temps sensible\n",
    "\n",
    "mask_sympo = False\n",
    "mask_geographique = True\n",
    "dir_fig = '../figures/total/'\n",
    "nsubzonesMax = 7\n",
    "plot_results = True\n",
    "if date == '2020012600':\n",
    "#     echeance_dict = {\n",
    "#         '38':[44,12,3,46,43,25,30],\n",
    "#         '29':[32,39,20,33,13],  \n",
    "#         '34':[1,5,6,4 ,10, 20,30], \n",
    "#         '41':[45,4,44,5,20,30]\n",
    "#     }\n",
    "        echeance_dict = {\n",
    "        '41':[30]\n",
    "    }\n",
    "if date == '2020030600':\n",
    "    echeance_dict = {\n",
    "        '38':[29,3,1,4,36],\n",
    "        '41':[18],\n",
    "        '29':[1,5,3],  \n",
    "        '34':[31,6,16,29,30], \n",
    "    }\n",
    "    \n",
    "for dep_id in echeance_dict.keys():\n",
    "    echeance_list = echeance_dict[dep_id]\n",
    "    print('dep_id',dep_id)\n",
    "    ''' lecture du mask '''\n",
    "    if mask_sympo and not mask_geographique: \n",
    "        fname_out = '../GeoData/zones_sympo_multiples/'+dep_id+'_mask_zones_sympos.nc'\n",
    "        if not os.path.exists(fname_out): \n",
    "            dir_mask = '/home/mrpa/borderiesm/stageEMI/Codes/StageEMI/Masques_netcdf/ZONE_SYMPO/'\n",
    "            list_subzones = glob.glob(dir_mask + dep_id +'*.nc')\n",
    "            n_subzones = len(list_subzones)  # nombre de zones sympos initiales\n",
    "            lst_subzones = [zone[-7:-3] for zone in list_subzones]\n",
    "            ds_mask = create_combination_subzones(dir_mask,dep_id,lst_subzones,fname_out,degre5=True) \n",
    "            ds_mask = ds_mask.chunk({\"id\":1})\n",
    "        else: \n",
    "            ds_mask = xr.open_dataset(fname_out,chunks={\"id\":1})\n",
    "\n",
    "    if mask_geographique and not mask_sympo: \n",
    "        if   dep_id == '38': dep = 'FRK24'\n",
    "        elif dep_id == '41': dep = 'FRB05'\n",
    "        elif dep_id == \"34\": dep = 'FRJ13'\n",
    "        elif dep_id == '29': dep = \"FRH02\"\n",
    "        else: \n",
    "            print('remplir la bonne valeur pour le dep')\n",
    "            sys.exit()\n",
    "        fname_out = '../GeoData/zones_sympo_multiples/'+ dep_id+'_'+dep+'_mask_NSEO.nc'\n",
    "        if not os.path.exists(fname_out):\n",
    "            dir_mask  = '../GeoData/nc_departement/'\n",
    "            dep_file  = dir_mask + dep +'.nc' \n",
    "            print('on cree',fname_out)\n",
    "            ds_mask = create_nc_mask_NSEO(dep_file,fname_out,plot_dep=False)\n",
    "            ds_mask = ds_mask.chunk({\"id\":1})\n",
    "        else:\n",
    "            ds_mask = xr.open_dataset(fname_out,chunks={\"id\":1})\n",
    "            \n",
    "    ds_mask[\"latitude\"]  = ds_mask[\"latitude\"].round(5)\n",
    "    ds_mask[\"longitude\"] = ds_mask[\"longitude\"].round(5)\n",
    "   \n",
    "    ''' lecture arome '''\n",
    "    fname = \"../WWMF/\" + date+'0000__PG0PAROME__'+'WWMF'+'__EURW1S100______GRILLE____0_48_1__SOL____GRIB2.nc'\n",
    "\n",
    "    ds = xr.open_dataset(fname,chunks={\"step\":1}).isel(step = echeance_list)\n",
    "    ds['latitude']  = ds['latitude'].round(5)\n",
    "    ds['longitude'] = ds['longitude'].round(5)\n",
    "    \n",
    "    ds_dep_tot = (ds*ds_mask.mask.sel(id=\"departement\").drop(\"id\"))\n",
    "#     ds_mask.sel(id= ds_mask.id[ds_mask.id_geo == 'departement'])\n",
    "    if date == '2020030600':\n",
    "        ds_dep_tot = ds_dep_tot.rename({'paramId_0':'unknown'})\n",
    "        \n",
    "    ''' calcul des temps agrégés '''\n",
    "    ds_distance_dict = {}\n",
    "    for name in list_name:\n",
    "        ds_distance         = distance_wwmf.get_pixel_distance_dept(ds_dep_tot,name)\n",
    "        ds_distance_chunk   = ds_distance.chunk({\"step\":1}) \n",
    "        ds_distance_dict[name] = (ds_distance_chunk * ds_mask.mask).sum(['latitude',\"longitude\"]).compute()\n",
    "    print('fin calcul distance')\n",
    "    \n",
    "    var_name = 'wme_arr'\n",
    "    for icheance,echeance in enumerate(echeance_list): \n",
    "        print(echeance)\n",
    "        fname_out = '../zonageWME/geo'+dep_id+'_'+date+'_'+str(echeance)+'.csv'\n",
    "        if os.path.exists(fname_out):\n",
    "            print(fname_out,'existe')\n",
    "            continue\n",
    "        \n",
    "        tdeb = time.time()\n",
    "        ''' on restreint la liste des WME pour le zonage '''\n",
    "        ds_dep = ds_dep_tot.isel(step = icheance).copy()\n",
    "        # on regroupe 'Très nuageux/Couvert' et 'Nuageux'\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 2) + (ds_dep[var_name].values == 3) ), 2)\n",
    "\n",
    "        # on regroupe ensemble neige (10) et neige faible (7)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 7) + (ds_dep[var_name].values == 10)), 10)\n",
    "        \n",
    "        # on regroupe ensemble pluie (8) et pluie faible (6)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 8) + (ds_dep[var_name].values == 6)),8)\n",
    "\n",
    "        # on regroupe ensemble qlqs averses (12) et averses (14), et qlqs averses de neige (13)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 12) + (ds_dep[var_name].values == 13)\n",
    "                                  + (ds_dep[var_name].values == 14 )),14)\n",
    "\n",
    "        # on regroupe ensemble averses Orageuses (16) et Orages  (18)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 16) + (ds_dep[var_name].values == 18)),18)\n",
    "\n",
    "        file_CodesWWMF = '../utils/CodesWWMF.csv'\n",
    "        cible_list,legend_list = get_WME_legend(file_CodesWWMF, ds_dep)\n",
    "        print(cible_list,legend_list)\n",
    "\n",
    "        ''' zonage '''\n",
    "        listCible    = cible_list[::-1]\n",
    "        legend_cible = [] # pour stocker la légende du code WME\n",
    "        listMasksNew = ds_mask.id.values # on commence avec l'ensemble des masks\n",
    "\n",
    "        # liste de zones sympos initiales (pour checker à la fin si on a une info sur toutes les zones du département)\n",
    "        list_zones_sympos_initiales = [zone for zone in ds_mask.id.values if '+' not in zone]\n",
    "        print(list_zones_sympos_initiales)\n",
    "        sys.exit()\n",
    "        nsubzones    = 0\n",
    "        zones_cibles = {}\n",
    "        score_zones_cibles = {}\n",
    "        if len(listCible) == 0 : # si un département a le même temps sensible partout\n",
    "            zones_cibles[listCible[0]] = 'departement'\n",
    "        else: \n",
    "            for icible,cible in enumerate(listCible):\n",
    "                if nsubzones > nsubzonesMax: \n",
    "                    print('nombre de sous-zones trop grand')\n",
    "                    break \n",
    "                if nsubzones >1: \n",
    "                    # pour éviter que departement ne soit selectionné alors que des sous-zones de departement aient déjà été selectionnées.\n",
    "                    listMasksNew = [element for element in listMasksNew if element !='departement']\n",
    "\n",
    "                if len(listMasksNew)>60:\n",
    "                    #  on regroupe les masks selon leur taille pour aller plus vite \n",
    "                    groupe1,groupe2,groupe3,taille1,taille2  = group_masks_size(listMasksNew,ds_mask)\n",
    "                    # on selectionne le groupement de zones qui match l'objet météo\n",
    "                    groupe_mask_select = select_group_mask(ds_dep,cible,groupe1,groupe2,groupe3,taille1,taille2)\n",
    "                else: \n",
    "                    # on considère l'ensemble des masks\n",
    "                    groupe_mask_select = ds_mask.mask.sel(id=listMasksNew)\n",
    "                # on selectionne la zone optimale (selon le hss et la précision)\n",
    "                zones_optimales,score_hss,score_precision=get_optimal_subzone_v2(ds_dep, groupe_mask_select,cible,ds_mask)\n",
    "                if len(zones_optimales)==0:\n",
    "                    # pas de zone sélectionnée pour ce temps sensible\n",
    "                    continue\n",
    "                else: \n",
    "                    legend_cible.append(legend_list[::-1][icible])\n",
    "                    score_zones_cibles[cible] = score_hss\n",
    "                    zones_cibles[cible] = zones_optimales \n",
    "                    nsubzones +=1                          \n",
    "\n",
    "                ''' on check que la somme des zones n'est pas déjà égale au departement '''\n",
    "                if  (nsubzones== 1) and (len(zones_cibles[cible]) == 1) :\n",
    "                    ds_temp  = ds_mask.sel(id=zones_cibles[cible][0]).mask.copy()\n",
    "\n",
    "                elif (nsubzones== 1) and (len(zones_cibles[cible]) > 1): \n",
    "                    ds_temp  = ds_mask.sel(id=zones_cibles[cible][0]).mask.copy() \n",
    "                    ds_temp.values[(ds_temp.values == 1) + (ds_mask.sel(id=zones_cibles[cible][1]).mask.values ==1) ] = 1\n",
    "                else: \n",
    "                    for zone in zones_cibles[cible]:\n",
    "                        print(zone)\n",
    "                        ds_temp.values[(ds_temp.values == 1) + (ds_mask.sel(id=zone).mask.values ==1) ] = 1\n",
    "\n",
    "                somme = np.sum((ds_temp.values == 1)&( ds_mask.sel(id='departement').mask.values== 1))\n",
    "                tailleDep = np.sum( ds_mask.sel(id='departement').mask.values== 1)\n",
    "                if somme == tailleDep: \n",
    "                    print('on a atteint la taille du departement')\n",
    "                    break\n",
    "                # on récupère les zones non-incluses dans la zone sélectionnée\n",
    "                for zone in zones_cibles[cible]:\n",
    "                    listMasksNew, lst_mask_included = get_not_included_masks(ds_mask.mask.sel(id=zone)\n",
    "                                                    ,listMasksNew,ds_mask,flag_strictly_included=False)\n",
    "            # fin boucle sur cible\n",
    "            ''' on vérifie que toutes les zones du département sont dans les zones selectionnées '''\n",
    "            list_zones_select = sum([zones_cibles[cible] for cible in zones_cibles.keys()],[]) \n",
    "            zones_restantes = []\n",
    "            for zone_sympo in list_zones_sympos_initiales:\n",
    "                n = 0\n",
    "                for zone_select in list_zones_select: \n",
    "                    if zone_sympo in zone_select:\n",
    "                        n+=1\n",
    "                if n == 0 : \n",
    "                    zones_restantes.append(zone_sympo)\n",
    "        \n",
    "        print(zones_cibles)          \n",
    "        '''save results in csv'''\n",
    "        print('saving results')\n",
    "        \n",
    "        d = { 'zone':sum([zones_cibles[cible] for cible in zones_cibles.keys()],[]), \n",
    "            'cible_wme':sum([[cible]  if len(zones_cibles[cible])==1 else [cible,cible] for cible in zones_cibles.keys()],[]),\n",
    "            'hss' : sum([score_zones_cibles[cible] for cible in zones_cibles.keys()],[])}\n",
    "\n",
    "        if len(zones_restantes)>0:\n",
    "            d['zone'] += zones_restantes\n",
    "            d['hss'] += [np.nan for i in range(len(zones_restantes))]\n",
    "            d['cible_wme'] += [np.nan for i in range(len(zones_restantes))]\n",
    "        for name in list_name:\n",
    "            d[name] =  ds_distance_dict[name].wwmf_2[ds_distance_dict[name].argmin(\"wwmf_2\")].sel(id=d['zone']).isel(step=icheance).values\n",
    "        pd.DataFrame(data=d).to_csv(fname_out)\n",
    "        \n",
    "        ''' plot '''\n",
    "        if not plot_results: \n",
    "            continue\n",
    "        print('plot')\n",
    "        X,Y = np.meshgrid( ds_mask.longitude.values,ds_mask.latitude.values)\n",
    "        listMasks = [ds_mask.sel(id=id_ref) for id_ref in list_zones_sympos_initiales]\n",
    "\n",
    "        legende = string.ascii_lowercase\n",
    "        patches = []\n",
    "        fig,axes = plt.subplots(nrows=1,ncols =3,figsize  = (15,5))\n",
    "        ax = axes.flat\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.3)\n",
    "        var2plot_lst = ['unknown','wme_arr','w1_arr']\n",
    "        varmin_lst   = [0,1,0]\n",
    "        varmax_lst   = [99,19,30]\n",
    "        for iplot in range(3):\n",
    "            var2plot = ds_dep_tot[var2plot_lst[iplot]].isel(step = icheance) \n",
    "            if iplot == 0 : \n",
    "                cmap  = matplotlib.cm.jet\n",
    "            else: \n",
    "                cmap = matplotlib.cm.tab20b\n",
    "                     \n",
    "            varmin   = varmin_lst[iplot]\n",
    "            varmax   = varmax_lst[iplot] + 1        \n",
    "            clevs    = np.arange(varmin,varmax+1,1)\n",
    "            cs       = var2plot.plot.imshow(ax = ax[iplot],cmap=cmap,levels=clevs)\n",
    "            for icible,cible in enumerate(zones_cibles):\n",
    "                for zone_select in  zones_cibles[cible] :\n",
    "                    mask_ref = ds_mask.sel(id = zone_select)\n",
    "\n",
    "                    list_neighbours = find_neighbours(mask_ref,listMasks)\n",
    "                    lst_mask_not_included, lst_mask_included = get_not_included_masks(mask_ref.mask, list_neighbours,ds_mask,flag_strictly_included=True)\n",
    "                    for neighbours in lst_mask_not_included:\n",
    "                        ind = np.where((mask_ref.mask.values == 1) & (ds_mask.sel(id=neighbours).mask.values == 1))\n",
    "                        ax[iplot].scatter(X[ind],Y[ind],color='k',s=6)\n",
    "                    # \n",
    "                    # ajout de la legende\n",
    "                    indice_mask_ref = np.where(mask_ref.mask.values == 1)\n",
    "\n",
    "                    ax[iplot].text(X[indice_mask_ref].mean(),Y[indice_mask_ref].mean(),s=legende[icible],color='k',fontsize=15)\n",
    "                    ax[iplot].set_title(date+' + {} h'.format(echeance))\n",
    "                    if iplot ==0:\n",
    "                        label = zone_select +': '+ legend_cible[icible] + ' ({})'.format(cible)\n",
    "                        # ajout de l'agregation: \n",
    "                        for name in list_name: \n",
    "                            val_agrege = ds_distance_dict[name].wwmf_2[ds_distance_dict[name].argmin(\"wwmf_2\")].sel(id=zone_select).isel(step=icheance).values\n",
    "                            label += ' {}:{}'.format(name,val_agrege)\n",
    "                if iplot == 0:\n",
    "                    patches.append(mlines.Line2D([],[],label = label,marker='${}$'.format(legende[icible]),color='black'))\n",
    "        lgd = ax[2].legend(handles=patches,bbox_to_anchor=(0.5,-0.2), loc='upper right',labelspacing =2,fontsize = 14)\n",
    "        fig.tight_layout()\n",
    "        fname_fig = dir_fig + 'v6_zonage_'+dep_id+date+'_'+str(echeance)+'.png'\n",
    "        print(fname_fig)\n",
    "        fig.savefig(fname_fig,dpi=400,bbox_inches='tight',format='png',bbox_extra_artists=(lgd,),)\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        print('temps',time.time()-tdeb)\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
