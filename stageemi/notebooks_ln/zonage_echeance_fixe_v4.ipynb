{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6c7f5b97fa55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;31m#,far,f1, pod,pofd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_combination_subzones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_nc_mask_NSEO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_neighbours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_optimal_subzone_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_masks_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_group_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_WME_legend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_not_included_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MeteoFrance_Remote/Code/stageemi/stageemi/notebooks_ln/lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# dans ce code on cherche à définir plusieurs zones à une échéance fixe\n",
    "# v2: possibilité de selectionner +sieurs zones pour un temps sensible critique donné \n",
    "# import sklearn.metrics\n",
    "import numpy as np\n",
    "import glob\n",
    "import xarray as xr \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import sys, os\n",
    "import string\n",
    "from pathlib import Path # pour windows \n",
    "sys.path.insert(0, os.path.abspath('./lib'))\n",
    "\n",
    "from lib import hss,precision #,far,f1, pod,pofd\n",
    "from lib import create_combination_subzones, create_nc_mask_NSEO\n",
    "from lib import find_neighbours,get_optimal_subzone_v2, group_masks_size, select_group_mask, get_WME_legend, get_not_included_masks\n",
    "from lib import cree_dict_agglo_insee, cree_ds_all_agglo, cree_dict_list_agglo\n",
    "\n",
    "import stageemi\n",
    "import stageemi.dev.distance_wwmf as distance_wwmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['legend.handlelength'] = 0\n",
    "matplotlib.rcParams['legend.numpoints'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' input '''\n",
    "# date = '2020012600'\n",
    "date = '2020030600'\n",
    "list_name = ['compas','agat','compas_asym','agat_asym'] # pour agreger le temps sensible\n",
    "\n",
    "mask_sympo = True\n",
    "mask_geographique = False\n",
    "dir_fig = '../figures/total/'\n",
    "nsubzonesMax = 7\n",
    "plot_results = True\n",
    "if date == '2020012600':\n",
    "    echeance_dict = {\n",
    "        '38':[44,12,3,46,43,25,30],\n",
    "        '29':[32,39,20,33,13],  \n",
    "        '34':[1,5,6,4 ,10, 20,30], \n",
    "        '41':[45,4,44,5,20,30]\n",
    "    }\n",
    "if date == '2020030600':\n",
    "    echeance_dict = {\n",
    "#         '38':[29,3,1,4,36],\n",
    "#         '41':[18],\n",
    "        '29':[1,5,3],  \n",
    "        '34':[31,6,16,29,30], \n",
    "    }\n",
    "    \n",
    "for dep_id in echeance_dict.keys():\n",
    "    echeance_list = echeance_dict[dep_id]\n",
    "    print('dep_id',dep_id)\n",
    "    ''' lecture du mask '''\n",
    "    if mask_sympo and not mask_geographique: \n",
    "        t1 = time.time()\n",
    "        fname_out = '../GeoData/zones_sympo_multiples/'+dep_id+'_mask_zones_sympos.nc'\n",
    "        if not os.path.exists(fname_out): \n",
    "            dir_mask = '/home/mrpa/borderiesm/stageEMI/Codes/StageEMI/Masques_netcdf/ZONE_SYMPO/'\n",
    "            list_subzones = glob.glob(dir_mask + dep_id +'*.nc')\n",
    "            n_subzones = len(list_subzones)  # nombre de zones sympos initiales\n",
    "            lst_subzones = [zone[-7:-3] for zone in list_subzones]\n",
    "            ds_mask = create_combination_subzones(dir_mask,dep_id,lst_subzones,fname_out,degre5=True) \n",
    "        else: \n",
    "            ds_mask = xr.open_dataset(fname_out,chunks={\"id\":1})\n",
    "            ds_mask[\"latitude\"]  = ds_mask[\"latitude\"].round(5)\n",
    "            ds_mask[\"longitude\"] = ds_mask[\"longitude\"].round(5)\n",
    "        print(time.time() - t1)\n",
    "\n",
    "    if mask_geographique and not mask_sympo: \n",
    "        dir_mask  = '/home/mrpa/borderiesm/stageEMI/Codes/stageemi/stageemi/GeoData/nc_departement/'\n",
    "        if   dep_id == '38': dep = 'FRK24'\n",
    "        elif dep_id == '41': dep = 'FRB05'\n",
    "        elif dep_id == \"34\": dep = 'FRJ13'\n",
    "        elif dep_id == '29': dep = \"FRH02\"\n",
    "        else: \n",
    "            print('remplir la bonne valeur pour le dep')\n",
    "            sys.exit()\n",
    "        dep_file  = dir_mask + dep +'.nc' \n",
    "        fname_out = '/home/mrpa/borderiesm/stageEMI/Codes/StageEMI/Masques_netcdf/ZONE_SYMPO_MULTIPLE/'+ dep_id+'_'+dep+'_mask_NSEO.nc'\n",
    "\n",
    "        if not os.path.exists(fname_out):\n",
    "            ds_mask = create_nc_mask_NSEO(dep_file,fname_out)\n",
    "        else:\n",
    "            ds_mask = xr.open_dataset(fname_out,chunks={\"id\":1})\n",
    "            ds_mask[\"latitude\"]  = ds_mask[\"latitude\"].round(5)\n",
    "            ds_mask[\"longitude\"] = ds_mask[\"longitude\"].round(5)\n",
    "    ''' lecture arome '''\n",
    "    fname = \"../WWMF/\" + date+'0000__PG0PAROME__'+'WWMF'+'__EURW1S100______GRILLE____0_48_1__SOL____GRIB2.nc'\n",
    "\n",
    "    ds = xr.open_dataset(fname,chunks={\"step\":1}).isel(step = echeance_list)\n",
    "    ds['latitude']  = ds['latitude'].round(5)\n",
    "    ds['longitude'] = ds['longitude'].round(5)\n",
    "    \n",
    "    if mask_sympo and not mask_geographique: \n",
    "        ds_dep_tot = (ds*ds_mask.mask.sel(id=\"departement\").drop(\"id\"))\n",
    "    if mask_geographique and not mask_sympo: \n",
    "        ds_dep_tot = (ds*ds_mask.mask.sel(id=\"mask\").drop(\"id\"))\n",
    "    if date == '2020030600':\n",
    "        ds_dep_tot = ds_dep_tot.rename({'paramId_0':'unknown'})\n",
    "        \n",
    "    ''' calcul des temps agrégés '''\n",
    "    ds_distance_dict = {}\n",
    "    for name in list_name:\n",
    "        ds_distance         = distance_wwmf.get_pixel_distance_dept(ds_dep_tot,name)\n",
    "        ds_distance_chunk   = ds_distance.chunk({\"step\":1}) \n",
    "        ds_distance_dict[name] = (ds_distance_chunk * ds_mask.mask).sum(['latitude',\"longitude\"]).compute()\n",
    "    print('fin calcul distance')\n",
    "    \n",
    "    var_name = 'wme_arr'\n",
    "    for icheance,echeance in enumerate(echeance_list): \n",
    "        print(echeance)\n",
    "        fname_out = '../zonageWME/'+dep_id+'_'+date+'_'+str(echeance)+'.csv'\n",
    "        if os.path.exists(fname_out):\n",
    "            print(fname_out,'existe')\n",
    "            continue\n",
    "        \n",
    "        tdeb = time.time()\n",
    "        ''' on restreint la liste des WME pour le zonage '''\n",
    "        ds_dep = ds_dep_tot.isel(step = icheance).copy()\n",
    "        # on regroupe 'Très nuageux/Couvert' et 'Nuageux'\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 2) + (ds_dep[var_name].values == 3) ), 2)\n",
    "\n",
    "        # on regroupe ensemble neige (10) et neige faible (7)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 7) + (ds_dep[var_name].values == 10)), 10)\n",
    "        \n",
    "        # on regroupe ensemble pluie (8) et pluie faible (6)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 8) + (ds_dep[var_name].values == 6)),8)\n",
    "\n",
    "        # on regroupe ensemble qlqs averses (12) et averses (14), et qlqs averses de neige (13)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 12) + (ds_dep[var_name].values == 13)\n",
    "                                  + (ds_dep[var_name].values == 14 )),14)\n",
    "\n",
    "        # on regroupe ensemble averses Orageuses (16) et Orages  (18)\n",
    "        ds_dep = ds_dep.where(~((ds_dep[var_name].values == 16) + (ds_dep[var_name].values == 18)),18)\n",
    "\n",
    "        file_CodesWWMF = '../utils/CodesWWMF.csv'\n",
    "        cible_list,legend_list = get_WME_legend(file_CodesWWMF, ds_dep)\n",
    "        print(cible_list,legend_list)\n",
    "\n",
    "        ''' zonage '''\n",
    "        listCible    = cible_list[::-1]\n",
    "        legend_cible = [] # pour stocker la légende du code WME\n",
    "        listMasksNew = ds_mask.id.values # on commence avec l'ensemble des masks\n",
    "\n",
    "        # liste de zones sympos initiales (pour checker à la fin si on a une info sur toutes les zones du département)\n",
    "        list_zones_sympos_initiales = [zone for zone in ds_mask.id.values if len(zone) == 4]\n",
    "\n",
    "        nsubzones    = 0\n",
    "        zones_cibles = {}\n",
    "        score_zones_cibles = {}\n",
    "        if len(listCible) == 0 : # si un département a le même temps sensible partout\n",
    "            zones_cibles[listCible[0]] = 'departement'\n",
    "        else: \n",
    "            for icible,cible in enumerate(listCible):\n",
    "                if nsubzones > nsubzonesMax: \n",
    "                    print('nombre de sous-zones trop grand')\n",
    "                    break \n",
    "                if nsubzones >1: \n",
    "                    # pour éviter que departement ne soit selectionné alors que des sous-zones de departement aient déjà été selectionnées.\n",
    "                    listMasksNew = [element for element in listMasksNew if element !='departement']\n",
    "\n",
    "                if len(listMasksNew)>60:\n",
    "                    #  on regroupe les masks selon leur taille pour aller plus vite \n",
    "                    groupe1,groupe2,groupe3,taille1,taille2  = group_masks_size(listMasksNew,ds_mask)\n",
    "                    # on selectionne le groupement de zones qui match l'objet météo\n",
    "                    groupe_mask_select = select_group_mask(ds_dep,cible,groupe1,groupe2,groupe3,taille1,taille2)\n",
    "                else: \n",
    "                    # on considère l'ensemble des masks\n",
    "                    groupe_mask_select = ds_mask.mask.sel(id=listMasksNew)\n",
    "                # on selectionne la zone optimale (selon le hss et la précision)\n",
    "                zones_optimales,score_hss,score_precision=get_optimal_subzone_v2(ds_dep, groupe_mask_select,cible,ds_mask)\n",
    "                if len(zones_optimales)==0:\n",
    "                    # pas de zone sélectionnée pour ce temps sensible\n",
    "                    continue\n",
    "                else: \n",
    "                    legend_cible.append(legend_list[::-1][icible])\n",
    "                    score_zones_cibles[cible] = score_hss\n",
    "                    zones_cibles[cible] = zones_optimales \n",
    "                    nsubzones +=1                          \n",
    "\n",
    "                ''' on check que la somme des zones n'est pas déjà égale au departement '''\n",
    "                if  (nsubzones== 1) and (len(zones_cibles[cible]) == 1) :\n",
    "                    ds_temp  = ds_mask.sel(id=zones_cibles[cible][0]).mask.copy()\n",
    "\n",
    "                elif (nsubzones== 1) and (len(zones_cibles[cible]) > 1): \n",
    "                    ds_temp  = ds_mask.sel(id=zones_cibles[cible][0]).mask.copy() \n",
    "                    ds_temp.values[(ds_temp.values == 1) + (ds_mask.sel(id=zones_cibles[cible][1]).mask.values ==1) ] = 1\n",
    "                else: \n",
    "                    for zone in zones_cibles[cible]:\n",
    "                        print(zone)\n",
    "                        ds_temp.values[(ds_temp.values == 1) + (ds_mask.sel(id=zone).mask.values ==1) ] = 1\n",
    "\n",
    "                somme = np.sum((ds_temp.values == 1)&( ds_mask.sel(id='departement').mask.values== 1))\n",
    "                tailleDep = np.sum( ds_mask.sel(id='departement').mask.values== 1)\n",
    "                if somme == tailleDep: \n",
    "                    print('on a atteint la taille du departement')\n",
    "                    break\n",
    "                # on récupère les zones non-incluses dans la zone sélectionnée\n",
    "                for zone in zones_cibles[cible]:\n",
    "                    listMasksNew, lst_mask_included = get_not_included_masks(ds_mask.mask.sel(id=zone)\n",
    "                                                    ,listMasksNew,ds_mask,flag_strictly_included=False)\n",
    "            # fin boucle sur cible\n",
    "            ''' on vérifie que toutes les zones du département sont dans les zones selectionnées '''\n",
    "            list_zones_select = sum([zones_cibles[cible] for cible in zones_cibles.keys()],[]) # [zones_cibles[cible] for cible in zones_cibles.keys()]\n",
    "            zones_restantes = []\n",
    "            for zone_sympo in list_zones_sympos_initiales:\n",
    "                n = 0\n",
    "                for zone_select in list_zones_select: \n",
    "                    if zone_sympo in zone_select:\n",
    "                        n+=1\n",
    "                if n == 0 : \n",
    "                    zones_restantes.append(zone_sympo)\n",
    "        \n",
    "        print(zones_cibles)          \n",
    "        '''save results in csv'''\n",
    "        print('saving results')\n",
    "        \n",
    "        d = { 'zone':sum([zones_cibles[cible] for cible in zones_cibles.keys()],[]), \n",
    "            'cible_wme':sum([[cible]  if len(zones_cibles[cible])==1 else [cible,cible] for cible in zones_cibles.keys()],[]),\n",
    "            'hss' : sum([score_zones_cibles[cible] for cible in zones_cibles.keys()],[])}\n",
    "\n",
    "        if len(zones_restantes)>0:\n",
    "            d['zone'] += zones_restantes\n",
    "            d['hss'] += [np.nan for i in range(len(zones_restantes))]\n",
    "            d['cible_wme'] += [np.nan for i in range(len(zones_restantes))]\n",
    "        for name in list_name:\n",
    "            d[name] =  ds_distance_dict[name].wwmf_2[ds_distance_dict[name].argmin(\"wwmf_2\")].sel(id=d['zone']).isel(step=icheance).values\n",
    "        pd.DataFrame(data=d).to_csv(fname_out)\n",
    "        \n",
    "        ''' plot '''\n",
    "        if not plot_results: \n",
    "            continue\n",
    "        print('plot')\n",
    "        X,Y = np.meshgrid( ds_mask.longitude.values,ds_mask.latitude.values)\n",
    "        listMasks = [ds_mask.sel(id=id_ref) for id_ref in list_zones_sympos_initiales]\n",
    "\n",
    "        legende = string.ascii_lowercase\n",
    "        patches = []\n",
    "        fig,axes = plt.subplots(nrows=1,ncols =3,figsize  = (15,5))\n",
    "        ax = axes.flat\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.3)\n",
    "        var2plot_lst = ['unknown','wme_arr','w1_arr']\n",
    "        varmin_lst   = [0,1,0]\n",
    "        varmax_lst   = [99,19,30]\n",
    "        for iplot in range(3):\n",
    "            var2plot = ds_dep_tot[var2plot_lst[iplot]].isel(step = icheance) \n",
    "            if iplot == 0 : \n",
    "                cmap  = matplotlib.cm.jet\n",
    "            else: \n",
    "                cmap = matplotlib.cm.tab20b\n",
    "                     \n",
    "            varmin   = varmin_lst[iplot]\n",
    "            varmax   = varmax_lst[iplot] + 1        \n",
    "            clevs    = np.arange(varmin,varmax+1,1)\n",
    "            cs       = var2plot.plot.imshow(ax = ax[iplot],cmap=cmap,levels=clevs)\n",
    "            for icible,cible in enumerate(zones_cibles):\n",
    "                for zone_select in  zones_cibles[cible] :\n",
    "                    mask_ref = ds_mask.sel(id = zone_select)\n",
    "\n",
    "                    list_neighbours = find_neighbours(mask_ref,listMasks)\n",
    "                    lst_mask_not_included, lst_mask_included = get_not_included_masks(mask_ref.mask, list_neighbours,ds_mask,flag_strictly_included=True)\n",
    "                    for neighbours in lst_mask_not_included:\n",
    "                        ind = np.where((mask_ref.mask.values == 1) & (ds_mask.sel(id=neighbours).mask.values == 1))\n",
    "                        ax[iplot].scatter(X[ind],Y[ind],color='k',s=6)\n",
    "                    # \n",
    "                    # ajout de la legende\n",
    "                    indice_mask_ref = np.where(mask_ref.mask.values == 1)\n",
    "\n",
    "                    ax[iplot].text(X[indice_mask_ref].mean(),Y[indice_mask_ref].mean(),s=legende[icible],color='k',fontsize=15)\n",
    "                    ax[iplot].set_title(date+' + {} h'.format(echeance))\n",
    "                    if iplot ==0:\n",
    "                        label = zone_select +': '+ legend_cible[icible] + ' ({})'.format(cible)\n",
    "                        # ajout de l'agregation: \n",
    "                        for name in list_name: \n",
    "                            val_agrege = ds_distance_dict[name].wwmf_2[ds_distance_dict[name].argmin(\"wwmf_2\")].sel(id=zone_select).isel(step=icheance).values\n",
    "                            label += ' {}:{}'.format(name,val_agrege)\n",
    "                if iplot == 0:\n",
    "                    patches.append(mlines.Line2D([],[],label = label,marker='${}$'.format(legende[icible]),color='black'))\n",
    "        lgd = ax[2].legend(handles=patches,bbox_to_anchor=(0.5,-0.2), loc='upper right',labelspacing =2,fontsize = 14)\n",
    "        fig.tight_layout()\n",
    "        fname_fig = dir_fig + 'v5_zonage_'+dep_id+date+'_'+str(echeance)+'.png'\n",
    "        print(fname_fig)\n",
    "        fig.savefig(fname_fig,dpi=400,bbox_inches='tight',format='png',bbox_extra_artists=(lgd,),)\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        print('temps',time.time()-tdeb)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zones_cibles)\n",
    "print(score_zones_cibles)\n",
    "print(zones_restantes)\n",
    "[np.nan for i in range(len(zones_restantes)+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temps sensible critique dans les agglomerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if date == '2020030600':\n",
    "    echeance_dict = {\n",
    "#         '38':[29,3,1,4,36],\n",
    "#         '41':[18],\n",
    "        '29':[1,5,3],  \n",
    "        '34':[31,6,16,29,30], \n",
    "    }\n",
    "    \n",
    "\n",
    "dep_id = \"29\"\n",
    "file_CodesWWMF = '../utils/CodesWWMF.csv'\n",
    "fname = \"../WWMF/\" + date+'0000__PG0PAROME__'+'WWMF'+'__EURW1S100______GRILLE____0_48_1__SOL____GRIB2.nc'\n",
    "echeance_list = echeance_dict[dep_id]\n",
    "ds = xr.open_dataset(fname,chunks={\"step\":1}).isel(step = echeance_list)\n",
    "ds['latitude']  = ds['latitude'].round(5)\n",
    "ds['longitude'] = ds['longitude'].round(5)\n",
    "    \n",
    "# Codes wwme\n",
    "    ''' Creation d'un dictionnaire avec les differents temps sensible critiques pour une agglomeration '''\n",
    "df_WWMF = pandas.read_csv(file_CodesWWMF,usecols = (0,1,6,7),sep=',')\n",
    "dict_temps = dict()\n",
    "for iwwmf,wwmf in enumerate(df_WWMF[\"Code WWMF\"]):\n",
    "        if (iwwmf >= 13) :\n",
    "            # Permet de selectionner les temps critiques que l'on utilise ensuite dans les fonctions. \n",
    "            dict_temps[df_WWMF[\"Legende WME\"][iwwmf]]=df_WWMF[\"Code WME\"][iwwmf]\n",
    "            \n",
    "     # Codes insee             \n",
    "dir_CodesINSEE= '/home/mrgo/frevilleh/ProjetEMI/stageemi/stageemi/GeoData/'\n",
    "dir_mask_agglo = '/scratch/labia/chabotv/geo_data/TestEAS/MaskList/'\n",
    "\n",
    "\n",
    "if os.path.isfile(dir_CodesINSEE+'code_insee.csv') and os.path.isfile(dir_mask_agglo +'list_'+ dep_id +'.nc'):\n",
    "    print (\"Files exist\")\n",
    "    file_CodesINSEE = dir_CodesINSEE+'code_insee.csv'\n",
    "    df_INSEE = pandas.read_csv(file_CodesINSEE,usecols = (0,1,),sep=';')\n",
    "    ds_dep_agglo = read_xarray(dir_mask_agglo +'list_'+ dep_id +'.nc')\n",
    "          \n",
    "    dict_insee = cree_dict_agglo_insee(dep_id)\n",
    "    ds_agglo = cree_ds_all_agglo(ds,ds_dep_agglo)   \n",
    "    dict_agglo_tps_critique = cree_dict_list_agglo(dict_temps, ds_agglo, ds_dep_agglo)\n",
    "        \n",
    "else:\n",
    "    print (\"Files not exist\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
